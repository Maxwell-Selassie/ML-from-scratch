{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a483e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop the linear regression algorithm from scratch\n",
    "'''\n",
    "Workflow:\n",
    "    - Initialize parameters (w, b)\n",
    "    - Compute forward_pass z = (w @ x) + b\n",
    "    - Sigmoid function a = (⅟1 + np.exp(-z))\n",
    "    - compute cost = (⅟n_samples) * ∑-(ylog(y_pred) + (1-y)log(1 - y_pred))\n",
    "    - compute ∂/∂w = (1/n_samples) * (y - y_pred) @ X.T\n",
    "    - compute ∂/∂b = (1/n_samples) * ∑(y - y_pred)\n",
    "    - update parameters (w, b)\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LogisticRegressionFromScratch:\n",
    "    '''Develop the Logistic Regression Model From Scratch'''\n",
    "    def __init__(self, lr: float = 0.01, epochs: int = 2000) -> None:\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.cost_history = []\n",
    "\n",
    "    def initialize_parameters(self, n_features: int) -> None:\n",
    "        '''Initialize the model's parameters (w,b)'''\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0.0\n",
    "\n",
    "    def compute_forward_pass(self, X: np.ndarray) -> np.ndarray:\n",
    "        '''Compute the initial forward pass on initialized parameters\n",
    "        \n",
    "        Args:\n",
    "            X : feature matrix (n_samples, n_features)\n",
    "        Returns:\n",
    "            y_pred : predicted labels (n_samples,)\n",
    "        '''\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "\n",
    "        y_pred = X @ self.w + self.b\n",
    "        return y_pred\n",
    "\n",
    "    def compute_cost(self, y: np.ndarray, y_pred: np.ndarray) -> int | float:\n",
    "        '''Computes the cost (cross-entropy loss)\n",
    "        \n",
    "        Args:\n",
    "            y: True Labels\n",
    "            y_pred: Predicted labels\n",
    "\n",
    "        Returns:\n",
    "            Cost (scalar)\n",
    "        '''\n",
    "        n_samples = len(y)\n",
    "\n",
    "        cost = (1 / n_samples) * np.sum(- (y * np.log(y_pred + 1e-5) + (1 - y) * np.log(1 - y_pred + 1e - 5)))\n",
    "        return cost\n",
    "\n",
    "    def gradient(self, X: np.ndarray, y_pred: np.ndarray, y: np.ndarray) -> tuple:\n",
    "        '''Compute partial derivatives w.r.t. w and b\n",
    "        \n",
    "        Args:\n",
    "            X : feature_matrix\n",
    "            y_pred : Predicted labels\n",
    "            y :True labels\n",
    "            \n",
    "        Returns:\n",
    "            Derivatives w.r.t. w and b\n",
    "        '''\n",
    "        if isinstance(X,pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        error = y_pred - y\n",
    "\n",
    "        dw = (1 / n_samples) * np.dot(X.T, error)\n",
    "        db = (1 / n_samples) * np.sum(error)\n",
    "        return dw, db\n",
    "\n",
    "    def update_paramters(self, dw: np.ndarray, db: float) -> None:\n",
    "        '''Update the parameters of w and b\n",
    "        \n",
    "        Args:\n",
    "            dw : Derivative w.r.t. w\n",
    "            db : Derivative w.r.t. b\n",
    "        '''\n",
    "        self.w -= self.lr * dw\n",
    "        self.b -= self.lr * db"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
