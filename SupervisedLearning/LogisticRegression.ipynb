{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a483e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop the linear regression algorithm from scratch\n",
    "'''\n",
    "Workflow:\n",
    "    - Initialize parameters (w, b)\n",
    "    - Compute forward_pass z = (w @ x) + b\n",
    "    - Sigmoid function a = (⅟1 + np.exp(-z))\n",
    "    - compute cost = (⅟n_samples) * ∑-(ylog(y_pred) + (1-y)log(1 - y_pred))\n",
    "    - compute ∂/∂w = (1/n_samples) * (y - y_pred) @ X.T\n",
    "    - compute ∂/∂b = (1/n_samples) * ∑(y - y_pred)\n",
    "    - update parameters (w, b)\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LogisticRegressionFromScratch():\n",
    "    '''Develop the Logistic Regression Model From Scratch'''\n",
    "    def __init__(self, lr: float = 0.01, epochs: int = 5000) -> None:\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.cost_history = []\n",
    "\n",
    "    def initialize_parameters(self, n_features: int) -> None:\n",
    "        '''Initialize the model's parameters (w,b)'''\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0.0\n",
    "\n",
    "    def compute_forward_pass(self, X: np.ndarray) -> np.ndarray:\n",
    "        '''Compute the initial forward pass on initialized parameters\n",
    "        \n",
    "        Args:\n",
    "            X : feature matrix (n_samples, n_features)\n",
    "        Returns:\n",
    "            y_pred : predicted labels (n_samples,)\n",
    "        '''\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "\n",
    "        y_pred = X @ self.w + self.b\n",
    "        return y_pred\n",
    "\n",
    "    def compute_cost(self, y: np.ndarray, y_pred: np.ndarray) -> int | float:\n",
    "        '''Computes the cost (cross-entropy loss)\n",
    "        \n",
    "        Args:\n",
    "            y: True Labels\n",
    "            y_pred: Predicted labels\n",
    "\n",
    "        Returns:\n",
    "            Cost (scalar)\n",
    "        '''\n",
    "        n_samples = len(y)\n",
    "\n",
    "        cost = (1 / n_samples) * np.sum(- (y * np.log(y_pred + 1e-5) + (1 - y) * np.log(1 - y_pred + 1e-5)))\n",
    "        return cost\n",
    "\n",
    "    def sigmoid(self, z: np.ndarray) -> None:\n",
    "        '''Sigmoid Function'''\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def gradient(self, X: np.ndarray, y_pred: np.ndarray, y: np.ndarray) -> tuple:\n",
    "        '''Compute partial derivatives w.r.t. w and b\n",
    "        \n",
    "        Args:\n",
    "            X : feature_matrix\n",
    "            y_pred : Predicted labels\n",
    "            y :True labels\n",
    "            \n",
    "        Returns:\n",
    "            Derivatives w.r.t. w and b\n",
    "        '''\n",
    "        if isinstance(X,pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        error = y_pred - y\n",
    "\n",
    "        dw = (1 / n_samples) * np.dot(X.T, error)\n",
    "        db = (1 / n_samples) * np.sum(error)\n",
    "        return dw, db\n",
    "\n",
    "    def update_paramters(self, dw: np.ndarray, db: float) -> None:\n",
    "        '''Update the parameters of w and b\n",
    "        \n",
    "        Args:\n",
    "            dw : Derivative w.r.t. w\n",
    "            db : Derivative w.r.t. b\n",
    "        '''\n",
    "        self.w -= self.lr * dw\n",
    "        self.b -= self.lr * db\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> 'LogisticRegressionFromScratch':\n",
    "        '''Train logistic model from scratch\n",
    "        \n",
    "        Args: \n",
    "            X : feature matrix\n",
    "            y : true labels\n",
    "            \n",
    "        Returns:\n",
    "            A trained logistic regression model\n",
    "        '''\n",
    "        # convert X and y to numpy arrays if they are instances of a pandas dataframe\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            y = y.values\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        # initialize parameters\n",
    "        self.initialize_parameters(n_features)\n",
    "        \n",
    "        print('Training a Logistic Regression Model...')\n",
    "        for epoch in range(1, self.epochs+1) :\n",
    "            # forward pass\n",
    "            z = self.compute_forward_pass(X)\n",
    "            # Pass predictions into an activation function\n",
    "            y_pred = self.sigmoid(z)\n",
    "            # cost function\n",
    "            cost = self.compute_cost(y, y_pred)\n",
    "            self.cost_history.append(cost)\n",
    "\n",
    "            # partial derivatives w.r.t. w & b (gradients)\n",
    "            dw, db = self.gradient(X, y_pred, y)\n",
    "\n",
    "            # update parameters (w, b)\n",
    "            self.w -= self.lr * dw\n",
    "            self.b -= self.lr * db\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Cost after {epoch} epochs : {cost:.4f}') \n",
    "\n",
    "        print('Logistic Regression Model trained successfully')\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        '''Make predictions based on trained model'''\n",
    "        if self.w is None or self.b is None:\n",
    "            print(f'Model not yet trained. Call the \"fit\" function first')\n",
    "            raise\n",
    "\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # compute predictions\n",
    "        z = self.compute_forward_pass(X)\n",
    "\n",
    "        predictions = self.sigmoid(z)\n",
    "\n",
    "        # convert predictions to either 0 or 1 with a threshold of 0.5\n",
    "        threshold = 0.5\n",
    "        y_pred = (predictions >= threshold).astype(int)\n",
    "        return y_pred\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        '''Get learned learned parameters'''\n",
    "        return {\n",
    "            'weight' : self.w,\n",
    "            'bias' : self.b,\n",
    "            'final_cost' : self.cost_history[-1]\n",
    "        }\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Generate data for CLASSIFICATION\n",
    "    X = np.random.randn(100, 3)\n",
    "\n",
    "    true_w = np.array([3.0,-2.0,1.5])\n",
    "    true_b = 5.0\n",
    "\n",
    "    # Compute logits\n",
    "    logits = X @ true_w + true_b\n",
    "\n",
    "    # Apply sigmoid to get probabilities\n",
    "    probabilities = 1 / (1 + np.exp(-logits))\n",
    "\n",
    "    # Convert to binary labels (0 or 1)\n",
    "    y = (probabilities > 0.5).astype(int)\n",
    "\n",
    "    # Or add randomness based on probability\n",
    "    y = (np.random.rand(X.shape[0]) < probabilities).astype(int)\n",
    "\n",
    "    print('='*50)\n",
    "    print(f'SYNTHETIC DATA GENERATED')\n",
    "    print('='*50)\n",
    "    print(f'Samples : {X.shape[0]}')\n",
    "    print(f'Features : {X.shape[1]}')\n",
    "    print(f'True Weight : {true_w}')\n",
    "    print(f'True bias : {true_b}')\n",
    "    print('='*50)\n",
    "\n",
    "    # train model\n",
    "    model = LogisticRegressionFromScratch()\n",
    "    model.fit(X,y)\n",
    "\n",
    "    # get learned paramters\n",
    "    params = model.get_parameters()\n",
    "\n",
    "    print('='*50)\n",
    "    print('LEARNED PARAMETERS')\n",
    "    params_weight = params['weight']\n",
    "    params_bias = params['bias']\n",
    "    params_final_cost = params['final_cost']\n",
    "\n",
    "    print(f'Learned weight: {params_weight}')\n",
    "    print(f'Learned Bias : {params_bias}')\n",
    "    print(f'Final cost after training : {params_final_cost}')\n",
    "\n",
    "    # compare with true weight and bias\n",
    "    print('='*50)\n",
    "    print('DIFFERENCE B/N LEARNED AND TRUE PARAMETERS')\n",
    "    print('='*50)\n",
    "\n",
    "    weight_error = abs(true_b - params['weight'])\n",
    "    bias_error = abs(true_b - params[\"bias\"])\n",
    "\n",
    "    print(f'Weight Error : {weight_error}')\n",
    "    print(f'Bias Error : {bias_error}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
